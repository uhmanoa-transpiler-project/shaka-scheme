//
// Created by aytas on 10/31/2017.
//

#ifndef SHAKA_SCHEME_LEXER_DEFINITIONS_HPP
#define SHAKA_SCHEME_LEXER_DEFINITIONS_HPP

#include <iostream>
#include <sstream>
#include <string>
#include <vector>
#include <functional>

namespace shaka {
namespace lexer {

/**
 * @brief Stores the filename and string position tracking info.
 */
struct LexInfo {
  std::string filename;
  int pos;
  int row;
  int col;
};

bool operator==(LexInfo left, LexInfo right) {
  return (
    left.filename == right.filename
      && left.pos == right.pos
      && left.row == right.row
      && left.col == right.col
  );
}

bool operator!=(LexInfo left, LexInfo right) {
  return !operator==(left, right);
}

/**
 * @brief Prints out the LexInfo in a readable format.
 * @param left The output stream reference.
 * @param right The LexInfo object to print out.
 * @return The updated version of the output stream.
 */
std::ostream& operator<<(std::ostream& left, const LexInfo& right) {
  left << "LexInfo("
       << "name:\"" << right.filename << "\" | "
       << "pos:" << right.pos << " | "
       << "row:" << right.row << " | "
       << "col:" << right.col << ")";
  return left;
}

/**
 * @brief A simple class to store the result of a parse.
 */
struct LexResult {
  LexResult(std::string type,
              std::string str,
              LexInfo info = {"<generic-input>", 0, 0, 0},
              std::string token_type = "") :
      type(type),
      str(str),
      info(info),
      token_type(token_type) {}

  /**
   * @brief The object for tracking file position.
   */
  LexInfo info;

  /**
   * @brief The type of the current result. Usually error, token, or incomplete.
   */
  std::string type;

  /**
   * @brief The type of the token parsed.
   */
  std::string token_type;

  /**
   * @brief The contents of the token parsed or consumed by the token or
   * erronous parse.
   */
  std::string str;

  bool is_error() const { return type == "error"; }
  bool is_token() const { return type == "token"; }
  bool is_incomplete() const { return type == "incomplete"; }
};

/**
 * @brief A pseudo-constructor for an LexResult error.
 * @param str The part of input that caused the error.
 * @param info The lexical info of the starting position of the input.
 * @param token_type Description of the error.
 * @return The LexResult object with the type "error".
 */
LexResult Error(std::string str, LexInfo info, std::string token_type) {
  return LexResult("error", str, info, token_type);
}

/**
 * @brief A pseudo-constructor for a LexResult token.
 * @param str The string contents of the token.
 * @param info The lexical info of the starting position of the token in the
 * input.
 * @param token_type The "tag" for type for the token.
 * @return The constructed LexResult object with the type "token".
 */
LexResult Token(std::string str, LexInfo info, std::string token_type) {
  return LexResult("token", str, info, token_type);
}

/**
 * @brief A pseudo-constructor for a LexResult incomplete marker.
 * @param str Not used.
 * @param info The lexical info of where the parse left off.
 * @return The "incomplete"-marked LexResult object.
 */
LexResult Incomplete(std::string str, LexInfo info) {
  return LexResult("incomplete", "", info);
}

/**
 * @brief Prints out a readable form for the LexResult.
 * @param left The output stream to write to.
 * @param right The LexResult object to print.
 * @return The updated version of the output stream.
 */
std::ostream& operator<<(std::ostream& left, LexResult right) {
  left << "LexResult("
       << "type:[" << right.type << "] | "
       << "str:\"" << right.str << "\" | "
       << "info:" << right.info << " | "
       << "token_type:<" << right.token_type << ">)";
  return left;
}

/**
 * @brief An exception type for any Lexer exceptions.
 */
struct LexerException : public std::exception {
  std::string str;

  /**
   * @brief Takes in the error message string and the lexical info.
   * @param str The error message.
   * @param info The lexical info.
   */
  LexerException(std::string str, LexInfo info) {
    std::stringstream ss;
    ss << info;
    str += ": ";
    str += ss.str();
    this->str = str;
  }

  /**
   * @brief The error string automatically generated by the exception.
   * @return The generated error string.
   */
  const char * what() const noexcept {
    return str.c_str();
  }
};

/**
 * @brief A utility class for wrapping a string with a tracking index and
 * lexical info, with methods for peeking, getting, ungeting, and appending
 * input.
 */
struct LexerInput {
  std::string input;
  int curr;
  LexInfo info;

  /**
   * @brief Takes in the initial input string and the name of the "module" or
   * "filename" of origin.
   * @param input The input string to take input from.
   * @param name The name of the "marker" for the LexInfo.
   */
  LexerInput(std::string input, std::string name = "<generic-input>") :
      input(input) {
    curr = 0;
    info = {name, 1, 1, 1};
  }

  int index() {
    return curr;
  }

  char peek() {
    if (input[curr] == '\0' || input[curr] == EOF || curr >= input.length()) {
      throw LexerException("need more input", this->info);
    }
    return input[curr];
  }

  LexInfo get_info() {
    return info;
  }

  void set_info(LexInfo info) {
    this->info = info;
  }

  char get() {
    const char c = input[curr];
    // If at end of string, just send back end of string.
    if (curr >= input.length()) {
      throw LexerException("need more input", this->info);
    }
    // Change col and row if newline.
    if (c == '\n') {
      info.row++;
      info.col = 1;
    } else {
      info.col++;
    }
    // Always increment pos counter.
    info.pos++;
    // Move iterator forward.
    ++curr;
    //std::cout << "get: pos: " << curr + 1 << std::endl;
    //std::cout << "get-distance: " << this->index() << " | " <<
    //          static_cast<char>
    //          (c) << std::endl;
    return c;
  }

  LexInfo info_then_get() {
    auto info = this->info;
    this->get();
    return info;
  }

  void unget(std::vector<LexResult> tokens) {
    //std::cout << "unget: before-tokens: " << std::endl;
    //for (auto it : tokens) {
    //  std::cout << it << std::endl;
    //}
    //std::cout << "unget: before: " << input << "|" << this->info <<
    //          std::endl;
    if (tokens.empty()) {
      return;
    }
    this->info = tokens[0].info;
    // Take the input.
    std::string temp;
    auto it_pos = this->index();
    //std::cout << "it_pos: " << it_pos << std::endl;
    for (auto i = curr; i < input.length(); ++i) {
      temp += input[i];
    }
    // Insert past input back into it.
    this->input = "";
    for (auto token : tokens) {
      //std::cout << "inserting token back: " << token.str << std::endl;
      this->input += token.str;
      for (auto i = 0; i < token.str.length(); ++i) {
        this->curr--;
      }
    }
    this->input += temp;
    this->curr = 0;
    //std::cout << "unget: after: " << input << "|" << this->info << std::endl;
  }

  void append_input(std::string more_input) {
    std::string temp;
    for (auto i = 0; i < input.length(); ++i) {
      temp += input[i];
    }
    temp += more_input;
    this->input = temp;
    curr = 0;
  }
};

using LexerRule = std::function<LexResult(LexerInput&)>;

auto sequence = [](LexerRule left,
                   LexerRule right,
                   std::string type = "") -> LexerRule {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    LexInfo saved_info = lex.get_info();
    std::string buf;

    auto lresult = left(lex);
    if (!lresult.is_token()) {
      return lresult;
    }
    //std::cout << "sequence: left: " << lresult << std::endl;
    auto rresult = right(lex);
    if (!rresult.is_token()) {
      lex.unget({lresult});
      return rresult;
    }
    //std::cout << "sequence: right: " << rresult << std::endl;

    buf += lresult.str;

    buf += rresult.str;

    std::string token_type = type;
    if (token_type.empty()) {
      token_type = lresult.token_type;
      token_type += "+";
      token_type += rresult.token_type;
    }
    return Token(buf, saved_info, token_type);
  };
};

auto make_terminal = [](std::string str, std::string type = "") -> LexerRule {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    LexInfo saved_info = lex.get_info();
    std::string buf;

    try {
      // If we matched to the entire string.
      bool valid = true;
      // For each character in the terminal string,
      // try to match the next input to it.
      for (auto it : str) {
        if (lex.peek() != it) {
          valid = false;
          break;
        }
        buf += lex.peek();
        lex.get();
      }
      // If we got through the entire array without error, return the token.
      if (valid) {
        return Token(buf, saved_info, type);
      } else {
        // If an error, unget the token.
        auto token = Token(buf, saved_info, type);
        lex.unget({token});
        return Error(buf, lex.get_info(), std::string(type) + ": "
            "could not match to \"" + str + "\"");
      }
    } catch (LexerException e) {
      return Incomplete(e.what(), lex.get_info());
    }
  };
};

auto make_class = [](std::function<bool(char)> pred, std::string type) {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    LexInfo saved_info = lex.get_info();
    std::string buf;

    try {
      // If we matched to the entire string.
      bool valid = true;
      // For each character in the terminal string,
      // try to match the next input to it.
      if (!pred(lex.peek())) {
        valid = false;
      }
      buf += lex.peek();
      lex.get();
      // If we got through the entire array without error, return the token.
      if (valid) {
        return Token(buf, saved_info, type);
      } else {
        // If an error, unget the token.
        auto token = Token(buf, saved_info, type);
        lex.unget({token});
        return Error(buf, lex.get_info(), std::string(type) + ": "
            "character did not pass predicate");
      }
    } catch (LexerException e) {
      return Incomplete(e.what(), lex.get_info());
    }
  };
};

LexerRule operator+(LexerRule left, LexerRule right) {
  return sequence(left, right);
}

auto alternative = [](LexerRule left,
                      LexerRule right,
                      std::string token_type = "") -> LexerRule {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    LexInfo saved_info = lex.get_info();
    std::string buf;

    auto lresult = left(lex);
    if (lresult.is_token() || lresult.is_incomplete()) {
      return lresult;
    }
    auto rresult = right(lex);
    if (rresult.is_token() || rresult.is_incomplete()) {
      return rresult;
    }
    return Error(rresult.str, saved_info, lresult.token_type +
        "|" + rresult.token_type);
  };
};

LexerRule operator|(LexerRule left, LexerRule right) {
  return alternative(left, right);
}

auto kleene = [](LexerRule rule) {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    LexInfo saved_info = lex.get_info();
    std::string buf;

    auto result = rule(lex);
    std::string token_type = result.token_type;
    if (!result.is_token()) {
      return Token("", saved_info, "empty");
    }
    //std::cout << result << std::endl;
    while (result.is_token()) {
      buf += result.str;
      result = rule(lex);
      //std::cout << result << std::endl;
    }
    return Token(buf, saved_info, "*" + token_type);
  };
};

LexerRule operator*(LexerRule rule) {
  return kleene(rule);
}

auto with_label = [](LexerRule rule, std::string label) {
  return [=](LexerInput& lex) -> LexResult {
    // Save the string and info before hand.
    auto result = rule(lex);
    if (result.is_token()) {
      result.token_type = label;
    }
    return result;
  };
};

LexerRule operator/(LexerRule rule, std::string right) {
  return with_label(rule, right);
}

auto empty_string = [](LexerInput& lex) {
  return Token("", lex.info, "empty");
};

LexerRule repeat(LexerRule rule, std::size_t times) {
  auto repeated_rule = rule;
  for (auto i = 1; i < times; ++i) {
    repeated_rule = repeated_rule + rule;
  }
  return repeated_rule;
}

LexerRule operator*(LexerRule rule, std::size_t right) {
  return repeat(rule, right);
}

LexerRule operator*(std::size_t left, LexerRule rule) {
  return repeat(rule, left);
}

LexerRule suffix_action(LexerRule rule,
                         std::function<LexResult(LexResult)> func) {
  return [=](LexerInput& lex) {
    auto result = rule(lex);
    return func(result);
  };
}

LexerRule operator&(LexerRule left, std::function<LexResult(LexResult)> func) {
  return suffix_action(left, func);
}

LexerRule prefix_action(LexerRule rule,
                         std::function<void(LexerInput&)> func) {
  return [=](LexerInput& lex) {
    func(lex);
    auto result = rule(lex);
    return result;
  };
}

LexerRule operator&(std::function<void(LexerInput&)> func, LexerRule rule) {
  return prefix_action(rule, func);
}

LexerRule reject_if(LexerRule rule) {
  return [=](LexerInput& lex) {
    auto result = rule(lex);
    if (result.is_token()) {
      lex.unget({result});
      return Error(result.str, result.info, "Error: rejection rule \"" + result
          .token_type + "\" triggered");
    } else if (result.is_error()) {
      return Token(result.str, result.info, result.token_type);
    } else {
      return result;
    }
  };
}

LexerRule operator!(LexerRule rule) {
  return reject_if(rule);
}

} // namespace lexer
} // namespace shaka

#endif //SHAKA_SCHEME_LEXER_DEFINITIONS_HPP
